{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8c735c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "from wl_kernel.kernel import WLkernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b69bca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graphs_from_dir(directory):\n",
    "    graphs = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".gpickle\"):\n",
    "            path = os.path.join(directory, filename)\n",
    "            with open(path, \"rb\") as f:\n",
    "                G = pickle.load(f)\n",
    "            graphs.append((filename, G))\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16855024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_vector(vector):\n",
    "    if np.sum(vector) == 0:\n",
    "        return 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "    prob = vector / np.sum(vector)\n",
    "    prob = prob[prob > 0]\n",
    "    ent = entropy(prob, base=2)\n",
    "    var = np.var(vector)\n",
    "    sparsity = np.count_nonzero(vector) / len(vector)\n",
    "    norm = np.linalg.norm(vector)\n",
    "\n",
    "    sparsity_penalty = abs(sparsity - 0.2)\n",
    "    score = (ent / (var + 1e-5)) / (norm + sparsity_penalty + 1e-5)\n",
    "    return ent, var, sparsity, norm, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac4d26b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_graphs(graphs, vector_sizes=[10, 20, 50, 100, 200, 300, 500, 1000, 1500, 2000, 2500], k=3):\n",
    "    rows = []\n",
    "    for name, G in graphs:\n",
    "        for size in vector_sizes:\n",
    "            kernel = WLkernel(G, k=k, size=size)\n",
    "            vec = kernel.degree_vector(3)\n",
    "            ent, var, sparsity, norm, score = score_vector(vec)\n",
    "            rows.append({\n",
    "                \"graph\": name,\n",
    "                \"vector_size\": size,\n",
    "                \"entropy\": ent,\n",
    "                \"variance\": var,\n",
    "                \"sparsity\": sparsity,\n",
    "                \"norm\": norm,\n",
    "                \"score\": score\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f205b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def visualize_results(df, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    metrics = [\"entropy\"]\n",
    "    for metric in metrics:\n",
    "        plt.figure()\n",
    "        grouped = defaultdict(list)\n",
    "        for _, row in df.iterrows():\n",
    "            match = re.match(r\"G_(\\d+)_\", row[\"graph\"])\n",
    "            if match:\n",
    "                n_nodes = int(match.group(1))\n",
    "                grouped[n_nodes].append(row)\n",
    "\n",
    "        for n_nodes, rows in grouped.items():\n",
    "            subdf = pd.DataFrame(rows)\n",
    "            mean_values = subdf.groupby(\"vector_size\")[metric].mean().reset_index()\n",
    "            plt.plot(mean_values[\"vector_size\"], mean_values[metric], label=f\"{n_nodes} nodes\")\n",
    "        plt.xlabel(\"Vector size\")\n",
    "        plt.ylabel(metric.capitalize())\n",
    "        plt.title(f\"{metric.capitalize()} vs Vector Size\")\n",
    "        plt.legend(fontsize=\"small\", loc=\"best\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f\"{metric}_vs_vector_size.png\"))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f757c55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Analiza završena. CSV i slike su sačuvane.\n"
     ]
    }
   ],
   "source": [
    "graph_dir = \"data/small_graph_dataset\"\n",
    "output_dir = \"vector_quality_plots\"\n",
    "graphs = load_graphs_from_dir(graph_dir)\n",
    "df = analyze_graphs(graphs)\n",
    "df.to_csv(\"vector_quality_analysis.csv\", index=False)\n",
    "visualize_results(df, output_dir=output_dir)\n",
    "print(\"✅ Analiza završena. CSV i slike su sačuvane.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c59918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d011a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
